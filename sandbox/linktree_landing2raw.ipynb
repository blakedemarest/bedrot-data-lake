{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4d8e3d",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # Cell 0 – Notebook preamble  \n",
    "# Autogenerate **Linktree Raw→Staging cleaner (CSV output)**.  \n",
    "# *Adapted from `LLM_cleaner_guidelines.md` per user override to use CSV.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a90fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Raw dir:     C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\raw\\linktree\n",
      "[INFO] Staging dir: C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\staging\\linktree\n"
     ]
    }
   ],
   "source": [
    "# %%  \n",
    "# Cell 1 – Imports & constants\n",
    "import os, json, argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PLATFORM      = \"linktree\"\n",
    "PROJECT_ROOT  = Path(os.environ[\"PROJECT_ROOT\"])\n",
    "\n",
    "RAW_DIR       = PROJECT_ROOT / \"raw\"     / PLATFORM\n",
    "STAGING_DIR   = PROJECT_ROOT / \"staging\" / PLATFORM   # will now hold CSV\n",
    "\n",
    "for _dir in (RAW_DIR, STAGING_DIR):\n",
    "    _dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[INFO] Raw dir:     {RAW_DIR}\")\n",
    "print(f\"[INFO] Staging dir: {STAGING_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7a4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  \n",
    "# Cell 2 – Helper: convert one NDJSON record to a clean dict\n",
    "METRIC_COLS = [\n",
    "    \"totalViews\",\n",
    "    \"uniqueViews\",\n",
    "    \"totalClicks\",\n",
    "    \"uniqueClicks\",\n",
    "    \"clickThroughRate\",\n",
    "]\n",
    "\n",
    "def record_to_row(rec: dict) -> dict:\n",
    "    \"\"\"Validate & coerce types for one record.\"\"\"\n",
    "    if \"date\" not in rec:\n",
    "        raise ValueError(\"Missing 'date' field\")\n",
    "    row = {\"date\": pd.to_datetime(rec[\"date\"], errors=\"coerce\")}\n",
    "    for col in METRIC_COLS:\n",
    "        row[col] = pd.to_numeric(rec.get(col), errors=\"coerce\")\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0473151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  \n",
    "# Cell 3 – Build a DataFrame from *.ndjson files\n",
    "def build_dataframe(files: list[Path]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            with fp.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    rows.append(record_to_row(json.loads(line)))\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {fp.name}: {e}\")\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No valid rows extracted from raw NDJSON\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "    df = df.sort_values(\"date\").drop_duplicates()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  \n",
    "# Cell 4 – CLI entry-point (as a string template)\n",
    "CLEANER_TEMPLATE = f'''\"\"\"\n",
    "linktree_landing2raw.py\n",
    "Landing → Raw cleaner for Linktree data.\n",
    "\n",
    "Guided by `LLM_cleaner_guidelines.md`.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "PLATFORM = \"linktree\"\n",
    "PROJECT_ROOT = Path(os.environ[\"PROJECT_ROOT\"])\n",
    "\n",
    "LANDING_DIR = PROJECT_ROOT / \"landing\" / PLATFORM\n",
    "RAW_DIR     = PROJECT_ROOT / \"raw\"      / PLATFORM\n",
    "\n",
    "for _dir in (LANDING_DIR, RAW_DIR):\n",
    "    _dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def transform_response(payload: dict) -> list[dict]:\n",
    "    \"\"\"Flatten GraphQL `getAccountAnalytics` → `overview` → `timeseries`.\"\"\"\n",
    "    try:\n",
    "        ts_rows = (\n",
    "            payload[\"data\"]\n",
    "                   [\"getAccountAnalytics\"]\n",
    "                   [\"overview\"]\n",
    "                   [\"timeseries\"]\n",
    "        )\n",
    "    except (KeyError, TypeError):\n",
    "        print(\"[ERROR] Unexpected GraphQL structure.\")\n",
    "        return []\n",
    "\n",
    "    return [{{\n",
    "        \"date\":              r.get(\"date\"),\n",
    "        \"totalViews\":        r.get(\"totalViews\"),\n",
    "        \"uniqueViews\":       r.get(\"uniqueViews\"),\n",
    "        \"totalClicks\":       r.get(\"totalClicks\"),\n",
    "        \"uniqueClicks\":      r.get(\"uniqueClicks\"),\n",
    "        \"clickThroughRate\":  r.get(\"clickThroughRate\"),\n",
    "        \"__typename\":        r.get(\"__typename\")\n",
    "    }} for r in ts_rows]\n",
    "\n",
    "def process_file(in_path: Path) -> int:\n",
    "    out_path = RAW_DIR / f\"{{in_path.stem}}.ndjson\"\n",
    "    written  = 0\n",
    "    try:\n",
    "        with in_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            payload = json.load(f)\n",
    "        rows = transform_response(payload)\n",
    "        if not rows:\n",
    "            return 0\n",
    "        with out_path.open(\"w\", encoding=\"utf-8\") as out_f:\n",
    "            for row in rows:\n",
    "                json.dump(row, out_f, ensure_ascii=False)\n",
    "                out_f.write(\"\\\\n\")\n",
    "                written += 1\n",
    "        print(f\"[RAW]  {{in_path.name}} → {{out_path.name}} ({{written}} rows)\")\n",
    "        return written\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {{in_path.name}}: {{e}}\")\n",
    "        return 0\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Linktree Landing→Raw cleaner\")\n",
    "    parser.add_argument(\n",
    "        \"--file\", help=\"Process a single landing JSON file\", default=None\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    files = (\n",
    "        [Path(args.file)]\n",
    "        if args.file else\n",
    "        sorted(LANDING_DIR.glob(\"*.json\"))\n",
    "    )\n",
    "\n",
    "    total_rows = 0\n",
    "    for fp in files:\n",
    "        total_rows += process_file(fp)\n",
    "\n",
    "    if total_rows == 0:\n",
    "        raise RuntimeError(\"No records processed; aborting.\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[INFO] Completed run at {{timestamp}} – {{total_rows}} rows total.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f5933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cleaner written to src\\linktree\\cleaners\\linktree_raw2staging.py\n"
     ]
    }
   ],
   "source": [
    "# %%  \n",
    "# Cell 5 – Write the cleaner script to disk\n",
    "cleaner_dir = PROJECT_ROOT / \"src\" / \"linktree\" / \"cleaners\"\n",
    "cleaner_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "outfile = cleaner_dir / \"linktree_raw2staging.py\"\n",
    "outfile.write_text(CLEANER_TEMPLATE, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[INFO] Cleaner written to {outfile.relative_to(PROJECT_ROOT)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd3a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
