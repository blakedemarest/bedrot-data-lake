{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf43ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ PROJECT_ROOT: C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\n",
      "✔ raw_dir: C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\raw\\tiktok\n",
      "✔ staging_dir: C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\staging\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 1: Setup ───────────────────────────────────────────────────────────────\n",
    "import os, glob, zipfile, tempfile, shutil\n",
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ Load PROJECT_ROOT from your environment\n",
    "PROJECT_ROOT = os.getenv(\"PROJECT_ROOT\")\n",
    "if not PROJECT_ROOT:\n",
    "    raise EnvironmentError(\"PROJECT_ROOT is not set in environment\")\n",
    "\n",
    "# 2️⃣ Define raw and staging directories\n",
    "raw_dir     = os.path.join(PROJECT_ROOT, \"raw\",     \"tiktok\")\n",
    "staging_dir = os.path.join(PROJECT_ROOT, \"staging\")\n",
    "\n",
    "# 3️⃣ Ensure both raw/tiktok and staging exist\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(staging_dir, exist_ok=True)\n",
    "\n",
    "print(\"✔ PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"✔ raw_dir:\", raw_dir)\n",
    "print(\"✔ staging_dir:\", staging_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f890a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Loaded existing staging (730 rows)\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 2: Load Existing Staging Data ─────────────────────────────────────────\n",
    "staging_file = os.path.join(staging_dir, \"tiktok.csv\")\n",
    "\n",
    "if os.path.exists(staging_file):\n",
    "    staging_df = pd.read_csv(staging_file, parse_dates=[\"Date\"])\n",
    "    print(f\"✔ Loaded existing staging ({len(staging_df)} rows)\")\n",
    "else:\n",
    "    staging_df = pd.DataFrame(columns=[\"Artist\",\"Date\",\"Video Views\",\"Profile Views\",\"Likes\",\"Comments\",\"Shares\",\"Year\"])\n",
    "    print(\"ℹ No existing staging file; starting fresh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976bfde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Loaded latest raw snapshots:\n",
      "   • zone.a0: Overview_2024-05-28_1748345895_zone.a0.csv (365 rows)\n",
      "   • pig1987: Overview_2024-05-28_1748345902_pig1987.csv (365 rows)\n",
      "→ Combined raw_df: 730 rows across 2 artists\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 3: Load Latest Raw Snapshots per Artist ───────────────────────────────\n",
    "raw_files = glob.glob(os.path.join(raw_dir, \"*.csv\"))\n",
    "if not raw_files:\n",
    "    raise FileNotFoundError(f\"No CSVs found in raw directory: {raw_dir}\")\n",
    "\n",
    "# pick newest file per artist\n",
    "latest_raw = {}\n",
    "for fpath in raw_files:\n",
    "    base   = os.path.splitext(os.path.basename(fpath))[0]\n",
    "    artist = base.split(\"_\")[-1]   # e.g. \"zone.a0\" or \"pig1987\"\n",
    "    mtime  = os.path.getmtime(fpath)\n",
    "    if artist not in latest_raw or mtime > latest_raw[artist][1]:\n",
    "        latest_raw[artist] = (fpath, mtime)\n",
    "\n",
    "# load each and tag\n",
    "frames = []\n",
    "for artist, (fpath, _) in latest_raw.items():\n",
    "    df = pd.read_csv(fpath, parse_dates=[\"Date\"])\n",
    "    df[\"Artist\"] = artist\n",
    "    frames.append(df)\n",
    "\n",
    "raw_df = pd.concat(frames, ignore_index=True)\n",
    "print(\"✔ Loaded latest raw snapshots:\")\n",
    "for artist, (fpath, _) in latest_raw.items():\n",
    "    print(f\"   • {artist}: {os.path.basename(fpath)} ({len(pd.read_csv(fpath))} rows)\")\n",
    "print(f\"→ Combined raw_df: {len(raw_df)} rows across {raw_df['Artist'].nunique()} artists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02f9e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ pig1987: 0 new rows since 2025-05-27\n",
      "ℹ zone.a0: 0 new rows since 2025-05-27\n",
      "ℹ No new rows to append; staging unchanged\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 4: Append New Data Without Overwriting  ────────────────────────\n",
    "if staging_df.empty:\n",
    "    # First run ever\n",
    "    combined = raw_df.copy()\n",
    "    print(f\"ℹ No existing staging; using all {len(combined)} rows\")\n",
    "else:\n",
    "    # figure out what’s new per artist\n",
    "    last_dates = staging_df.groupby(\"Artist\")[\"Date\"].max().to_dict()\n",
    "    new_list   = []\n",
    "    for artist, grp in raw_df.groupby(\"Artist\"):\n",
    "        cutoff = last_dates.get(artist, pd.Timestamp.min)\n",
    "        new    = grp[grp[\"Date\"] > cutoff]\n",
    "        print(f\"ℹ {artist}: {len(new)} new rows since {cutoff.date()}\")\n",
    "        if not new.empty:\n",
    "            # align to staging schema exactly\n",
    "            new = new.reindex(columns=staging_df.columns)\n",
    "            new_list.append(new)\n",
    "    if new_list:\n",
    "        new_rows = pd.concat(new_list, ignore_index=True)\n",
    "        combined = pd.concat([staging_df, new_rows], ignore_index=True)\n",
    "        # dedupe on (Artist, Date)\n",
    "        combined = combined.drop_duplicates(subset=[\"Artist\",\"Date\"], keep=\"last\")\n",
    "        combined = combined.sort_values([\"Artist\",\"Date\"]).reset_index(drop=True)\n",
    "        print(f\"✔ Appended {len(new_rows)} rows → combined now {len(combined)} total\")\n",
    "    else:\n",
    "        combined = staging_df.copy()\n",
    "        print(\"ℹ No new rows to append; staging unchanged\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb3a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Staging updated: C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\staging\\tiktok.csv\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 5: Write Combined Data to Staging ─────────────────────────────────────\n",
    "combined.to_csv(staging_file, index=False)\n",
    "print(f\"✔ Staging updated: {staging_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82490a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
