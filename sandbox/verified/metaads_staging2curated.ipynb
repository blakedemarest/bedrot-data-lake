{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfdbec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell 1: Imports & Environment Setup ────────────────────────────────────────\n",
    "import os, hashlib, datetime, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = Path(os.getenv(\"PROJECT_ROOT\"))\n",
    "STAGING = PROJECT_ROOT / os.getenv(\"STAGING_ZONE\",  \"staging\")\n",
    "CURATED = PROJECT_ROOT / os.getenv(\"CURATED_ZONE\",  \"curated\")\n",
    "ARCHIVE = PROJECT_ROOT / os.getenv(\"ARCHIVE_ZONE\",  \"archive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ecef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell 2: Append ONLY brand-new (date_start, ad_id) rows ────────────────────\n",
    "src = STAGING / \"tidy_metaads.csv\"\n",
    "\n",
    "# 1️⃣  Load staging, drop exact dupes inside the file itself\n",
    "new = (pd.read_csv(src, parse_dates=[\"date_start\",\"date_stop\"], low_memory=False)\n",
    "         .drop_duplicates(subset=[\"date_start\",\"ad_id\"]))\n",
    "\n",
    "# Build PK\n",
    "new[\"_pk\"] = new[[\"date_start\",\"ad_id\"]].astype(str).agg(\"|\".join, axis=1)\n",
    "\n",
    "cur_path = CURATED / \"metaads_campaigns_daily.csv\"\n",
    "if cur_path.exists():\n",
    "    cur = (pd.read_csv(cur_path, parse_dates=[\"date_start\",\"date_stop\"], low_memory=False)\n",
    "             .drop_duplicates(subset=[\"date_start\",\"ad_id\"]))          # ensure tidy history\n",
    "    cur[\"_pk\"] = cur[[\"date_start\",\"ad_id\"]].astype(str).agg(\"|\".join, axis=1)\n",
    "\n",
    "    # 2️⃣  Keep only brand-new PKs\n",
    "    append_only = new[~new[\"_pk\"].isin(cur[\"_pk\"])].drop(columns=\"_pk\")\n",
    "    merged = pd.concat([cur.drop(columns=\"_pk\"), append_only], ignore_index=True)\n",
    "else:\n",
    "    cur_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    merged = new.drop(columns=\"_pk\")\n",
    "\n",
    "# 3️⃣  Sort for readability\n",
    "merged = merged.sort_values([\"date_start\",\"campaign_id\",\"adset_id\",\"ad_id\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe0fbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Curated updated – rows: 54\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 3: Save & archive if dataset changed ─────────────────────────────────\n",
    "def df_hash(df):  return hashlib.md5(df.to_csv(index=False).encode()).hexdigest()\n",
    "def file_hash(p): return hashlib.md5(p.read_bytes()).hexdigest()\n",
    "\n",
    "if cur_path.exists() and df_hash(merged) == file_hash(cur_path):\n",
    "    print(\"↩︎ No changes – curated already up-to-date.\")\n",
    "else:\n",
    "    if cur_path.exists():\n",
    "        ARCHIVE.mkdir(parents=True, exist_ok=True)\n",
    "        ts = datetime.datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "        shutil.copy2(cur_path, ARCHIVE / f\"metaads_campaigns_daily_{ts}.csv\")\n",
    "        print(\"📦 Archived previous version.\")\n",
    "    merged.to_csv(cur_path, index=False)\n",
    "    print(f\"✅ Curated updated – rows: {len(merged)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb19097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
