{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Cell 1 â€“ Imports\n",
    "# ------------------------------------------------------------\n",
    "# Make sure pandas is installed:  pip install pandas\n",
    "from pathlib import Path\n",
    "import re, json, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‚ Cell 2 â€“ Source & target paths\n",
    "# ------------------------------------------------------------\n",
    "distrokid_html = Path(r\"C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\landing\\distrokid\\streams\\streams_stats_20250522_085156.html\")\n",
    "apple_html     = Path(r\"C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\landing\\distrokid\\streams\\applemusic_stats_20250522_085156.html\")\n",
    "\n",
    "curated_dir    = Path(r\"C:\\Users\\Earth\\BEDROT PRODUCTIONS\\BEDROT DATA LAKE\\data_lake\\curated\")\n",
    "curated_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_csv        = curated_dir / \"daily_streams_distrokid.csv\"\n",
    "print(\"CSV will be saved to:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”Ž Cell 3 â€“ DistroKid daily extractor\n",
    "def extract_distrokid_daily(html_path: Path) -> pd.DataFrame:\n",
    "    text = html_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    m = re.search(r'\"id\"\\s*:\\s*\"trend365day\".+?\"dataProvider\"\\s*:\\s*\\[([^\\]]+)\\]', \n",
    "                  text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"trend365day chart not found in DistroKid HTML.\")\n",
    "    arr_text = \"[\" + m.group(1).strip() + \"]\"\n",
    "    arr_text = re.sub(r',\\s*\\]', ']', arr_text)\n",
    "    data     = json.loads(arr_text)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={\"category\": \"date\", \"column-1\": \"spotify_streams\"}, inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df[[\"date\", \"spotify_streams\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ Cell 4 â€“ Apple Music daily extractor\n",
    "def extract_apple_daily(html_path: Path) -> pd.DataFrame:\n",
    "    text = html_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    providers = []\n",
    "    for m in re.finditer(r'\"dataProvider\"\\s*:\\s*\\[([^\\]]+)\\]', text, re.DOTALL):\n",
    "        array_txt = \"[\" + m.group(1) + \"]\"\n",
    "        array_txt = re.sub(r',\\s*\\]', ']', array_txt)\n",
    "        try:\n",
    "            providers.append(json.loads(array_txt))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    if not providers:\n",
    "        raise ValueError(\"No dataProvider arrays found in Apple Music HTML.\")\n",
    "    data = max(providers, key=len)           # assume longest = daily\n",
    "    if len(data) < 50:\n",
    "        raise ValueError(\"Daily data array looks too short; check HTML.\")\n",
    "    first      = data[0]\n",
    "    date_key   = \"field\" if \"field\" in first else \"category\"\n",
    "    value_key  = \"value\" if \"value\" in first else (\"column-1\" if \"column-1\" in first else list(first.keys())[1])\n",
    "    df         = pd.DataFrame(data)\n",
    "    df.rename(columns={date_key: \"date\", value_key: \"apple_streams\"}, inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df[[\"date\", \"apple_streams\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ—ï¸ Cell 5 â€“ Combine the two sources\n",
    "dk_df    = extract_distrokid_daily(distrokid_html)\n",
    "apple_df = extract_apple_daily(apple_html)\n",
    "\n",
    "combined = (dk_df\n",
    "            .merge(apple_df, on=\"date\", how=\"outer\")\n",
    "            .sort_values(\"date\")\n",
    "            .fillna(0))\n",
    "\n",
    "combined[\"spotify_streams\"] = combined[\"spotify_streams\"].astype(int)\n",
    "combined[\"apple_streams\"]   = combined[\"apple_streams\"].astype(int)\n",
    "combined[\"combined_streams\"] = combined[\"spotify_streams\"] + combined[\"apple_streams\"]\n",
    "\n",
    "combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ’¾ Cell 6 â€“ Write CSV & confirm\n",
    "combined.to_csv(out_csv, index=False)\n",
    "print(f\"âœ…  Saved merged CSV to: {out_csv}\")\n",
    "print(f\"Rows: {len(combined)}, Date range: {combined['date'].min().date()} â†’ {combined['date'].max().date()}\")\n",
    "\n",
    "combined.tail()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
