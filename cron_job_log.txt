[INFO] Running extractors for common
[INFO] Running extractor: src\common\extractors\tiktok_shared.py
[INFO] Running extractor: src\common\extractors\__init__.py
[INFO] Running extractors for instagram
[INFO] Running cleaners for instagram
[INFO] Running extractors for linktree
[INFO] Running extractor: src\linktree\extractors\linktree_analytics_extractor.py
[INFO] Starting Linktree analytics extractor...
[cookies] linktree: already imported â€“ skipping.
[INFO] Navigating to https://linktr.ee/admin/analytics ...
[ACTION REQUIRED] Please log in â€“ waiting for analytics dashboard to load...
[INFO] Logged in and analytics dashboard detected.
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074041_826444.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074041_913037.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074042_099950.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074042_157860.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074042_224720.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074042_394906.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074042_395415.json <- https://graph.linktr.ee/graphql
[INFO] Date range dropdown detected.
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074045_025344.json <- https://linktr.ee/api/graphql
[INFO] Selecting 'Last 365 days' timeframe...
[INFO] Selecting 'Daily' granularity...
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074047_627903.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074047_695049.json <- https://graph.linktr.ee/graphql
[SAVED] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\linktree\analytics\graphql_20250618_074047_775860.json <- https://graph.linktr.ee/graphql
[INFO] Now capturing GraphQL network responses. The browser will close automatically after extraction.
[INFO] No new GraphQL responses for 10 seconds. Closing browser...
[ERROR] Could not save response from https://graph.linktr.ee/graphql: : Target page, context or browser has been closed
[ERROR] Could not save response from https://graph.linktr.ee/graphql: : Target page, context or browser has been closed
[ERROR] Could not save response from https://graph.linktr.ee/graphql: : Target page, context or browser has been closed
[ERROR] Could not save response from https://graph.linktr.ee/graphql: : Target page, context or browser has been closed
[ERROR] Could not save response from https://graph.linktr.ee/graphql: : Target page, context or browser has been closed
[ERROR] Could not save response from https://graph.linktr.ee/graphql: : Target page, context or browser has been closed
[INFO] Browser closed. Extraction complete.
[INFO] Running cleaners for linktree
[INFO] Running cleaner: src\linktree\cleaners\linktree_landing2raw.py
Traceback (most recent call last):
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\linktree\cleaners\linktree_landing2raw.py", line 88, in <module>
    main()
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\linktree\cleaners\linktree_landing2raw.py", line 82, in main
    raise RuntimeError("No records processed; aborting.")
RuntimeError: No records processed; aborting.
[INFO] Running cleaner: src\linktree\cleaners\linktree_raw2staging.py
[STAGING] Written â†’ linktree_analytics_staging_20250618_074059.csv  (383 rows)
[INFO] Running cleaner: src\linktree\cleaners\linktree_staging2curated.py
C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\linktree\cleaners\linktree_staging2curated.py:28: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context("mode.use_inf_as_na", True):
[CURATED] CSV â†’ linktree_analytics_curated_20250618_074059.csv  (380 rows)
[CURATED] Parquet â†’ linktree_analytics_curated_20250618_074059.parquet
[CLEANUP] Archived older curated files â†’ archive\linktree
[INFO] Running extractors for mailchimp
[INFO] Running cleaners for mailchimp
[INFO] Running extractors for metaads
[INFO] Running extractor: src\metaads\extractors\meta_raw_dump.py
ðŸ”– Dump directory â†’ C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\metaads\meta_ads_dump_20250618_144100
Fetching campaigns â€¦
ðŸšš 17 campaigns saved
Fetching ad sets â€¦
ðŸšš 51 ad sets saved
Fetching ads â€¦
ðŸšš 74 ads saved
Fetching insights â€¦
Campaign insights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:16<00:00,  1.03it/s]
ðŸšš 51 insight rows saved
Rows â†’ campaigns: 17 | adsets: 51 | ads: 74 | insights: 51
ðŸ’° Lifetime spend snapshot: $2,293.50

âœ… Raw Meta snapshot complete â†’ C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\metaads\meta_ads_dump_20250618_144100
[INFO] Running cleaners for metaads
[INFO] Running cleaner: src\metaads\cleaners\metaads_landing2raw.py
â†©ï¸Ž meta_ads_dump_20250529_112751 already in RAW
â†©ï¸Ž meta_ads_dump_20250529_113628 already in RAW
â†©ï¸Ž meta_ads_dump_20250529_131842 already in RAW
â†©ï¸Ž meta_ads_dump_20250605_152903 already in RAW
â†©ï¸Ž meta_ads_dump_20250609_143936 already in RAW
â†©ï¸Ž meta_ads_dump_20250611_183340 already in RAW
â†©ï¸Ž meta_ads_dump_20250611_183837 already in RAW
â†©ï¸Ž meta_ads_dump_20250613_133651 already in RAW
â†©ï¸Ž meta_ads_dump_20250616_154645 already in RAW
âœ… promoted meta_ads_dump_20250618_144100
Summary: 1 new dump(s) promoted.
[INFO] Running cleaner: src\metaads\cleaners\metaads_raw2staging.py
Rows â†’ campaigns 17, adsets 51, ads 74, insights 51
ads_flat cols: ['ad_id', 'campaign_id', 'adset_id', 'ad_name', 'status', 'effective_status', 'created_time', 'updated_time', 'creative_id', 'tracking_specs']
campaigns_ cols: ['campaign_id', 'campaign_name', 'campaign_status', 'campaign_objective', 'start_time', 'created_time', 'updated_time']
adsets_ cols: ['adset_id', 'adset_name', 'adset_status', 'adset_daily_budget', 'adset_lifetime_budget', 'bid_strategy', 'targeting', 'optimization_goal', 'start_time', 'pacing_type', 'created_time', 'updated_time']
âœ… tidy_metaads â†’ C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging\tidy_metaads.csv  (rows: 74)
          campaign_id  ...                                     tracking_specs
0  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
1  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
2  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
3  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
4  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...

[5 rows x 38 columns]
[INFO] Running cleaner: src\metaads\cleaners\metaads_staging2curated.py
âœ… Curated updated â€“ rows: 74
[INFO] Running extractors for spotify
[INFO] Running extractor: src\spotify\extractors\spotify_audience_extractor.py
[INFO] Starting Spotify Audience extractor for 2 artist(s)â€¦
[cookies] spotify: already imported â€“ skipping.
[INFO] Navigating to https://artists.spotify.com/c/en/artist/62owJQCD2XzVB2o19CVsFM â€¦
[ACTION REQUIRED] Please log in to Spotify for Artists (2-FA if prompted)â€¦
[INFO] Audience nav link detected â€“ authentication complete.
[INFO] Clicked Audience nav link â†’ a#navigation-link-audience
[INFO] Audience page loaded for 62owJQCD2XzVB2o19CVsFM.
[INFO] Opening filter chipâ€¦
[WARN] Attempt 1/3 to click button[data-encore-id='chipFilter'] failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button[data-encore-id='chipFilter']").first to be visible

[INFO] Clicked Filters chip â†’ button[data-encore-id='chipFilter']
[INFO] Clicked 12-month label â†’ label[for='1year'], :text('12 months')
[WARN] Attempt 1/3 to click button:has-text('Done'), span:has-text('Done') failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button:has-text('Done'), span:has-text('Done')").first to be visible

[WARN] Attempt 2/3 to click button:has-text('Done'), span:has-text('Done') failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button:has-text('Done'), span:has-text('Done')").first to be visible

[WARN] Attempt 3/3 to click button:has-text('Done'), span:has-text('Done') failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button:has-text('Done'), span:has-text('Done')").first to be visible

[WARN] 'Done' button not clickable â€“ proceeding if CSV button is visible.
[INFO] 12-month filter applied (CSV button visible).
[INFO] Clicked CSV download button â†’ button[data-testid='csv-download']
[SAVED] CSV â†’ landing\spotify\audience\spotify_audience_62owJQCD2XzVB2o19CVsFM_20250618_074223.csv
[INFO] Navigating to https://artists.spotify.com/c/en/artist/1Eu67EqPy2NutiM0lqCarw â€¦
[INFO] Audience nav link detected â€“ authentication complete.
[INFO] Clicked Audience nav link â†’ a#navigation-link-audience
[INFO] Audience page loaded for 1Eu67EqPy2NutiM0lqCarw.
[INFO] Opening filter chipâ€¦
[WARN] Attempt 1/3 to click button[data-encore-id='chipFilter'] failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button[data-encore-id='chipFilter']").first to be visible

[WARN] Attempt 2/3 to click button[data-encore-id='chipFilter'] failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button[data-encore-id='chipFilter']").first to be visible

[INFO] Clicked Filters chip â†’ button[data-encore-id='chipFilter']
[INFO] Clicked 12-month label â†’ label[for='1year'], :text('12 months')
[WARN] Attempt 1/3 to click button:has-text('Done'), span:has-text('Done') failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button:has-text('Done'), span:has-text('Done')").first to be visible

[WARN] Attempt 2/3 to click button:has-text('Done'), span:has-text('Done') failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button:has-text('Done'), span:has-text('Done')").first to be visible

[WARN] Attempt 3/3 to click button:has-text('Done'), span:has-text('Done') failed: Locator.wait_for: Timeout 5000ms exceeded.
Call log:
  - waiting for locator("button:has-text('Done'), span:has-text('Done')").first to be visible

[WARN] 'Done' button not clickable â€“ proceeding if CSV button is visible.
[INFO] 12-month filter applied (CSV button visible).
[INFO] Clicked CSV download button â†’ button[data-testid='csv-download']
[SAVED] CSV â†’ landing\spotify\audience\spotify_audience_1Eu67EqPy2NutiM0lqCarw_20250618_074258.csv
[INFO] Browser closed. Extraction complete.
[INFO] Running cleaners for spotify
[INFO] Running cleaner: src\spotify\cleaners\spotify_staging2curated.py
[ERROR] [STAGING] No CSV files found to process.
[INFO] Running extractors for tiktok
[INFO] Running extractor: src\tiktok\extractors\tiktok_analytics_extractor_pig1987.py
[INFO] Running extractor: src\tiktok\extractors\tiktok_analytics_extractor_zonea0.py
Traceback (most recent call last):
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\tiktok\extractors\tiktok_analytics_extractor_zonea0.py", line 109, in <module>
    main()
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\tiktok\extractors\tiktok_analytics_extractor_zonea0.py", line 106, in main
    process_account_manual_persistent(playwright)
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\tiktok\extractors\tiktok_analytics_extractor_zonea0.py", line 93, in process_account_manual_persistent
    run_extraction(
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\common\extractors\tiktok_shared.py", line 97, in run_extraction
    page.get_by_role("button", name="Last 7 days").click()
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\.venv\Lib\site-packages\playwright\sync_api\_generated.py", line 15512, in click
    self._sync(
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\.venv\Lib\site-packages\playwright\_impl\_sync_base.py", line 115, in _sync
    return task.result()
           ^^^^^^^^^^^^^
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\.venv\Lib\site-packages\playwright\_impl\_locator.py", line 160, in click
    return await self._frame.click(self._selector, strict=True, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\.venv\Lib\site-packages\playwright\_impl\_frame.py", line 488, in click
    await self._channel.send("click", locals_to_params(locals()))
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 61, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 528, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TimeoutError: Locator.click: Timeout 30000ms exceeded.
Call log:
  - waiting for get_by_role("button", name="Last 7 days")

[INFO] Running cleaners for tiktok
[INFO] Running cleaner: src\tiktok\cleaners\tiktok_landing2raw.py
[INFO] PROJECT_ROOT: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake
[INFO] LANDING_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\tiktok\analytics
[INFO] RAW_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\raw\tiktok
[RAW] Found 2 artists: ['zone.a0', 'pig1987']
[RAW] Processing artist: zone.a0
[RAW] Loaded: Overview.csv (365 rows)
[RAW] Date rollover: 2024 â†’ 2025
[RAW] Transformed to 365 JSON records
[RAW] Written 365 records â†’ Overview_2024-06-12_1749649062_zone.a0_20250618_074347.ndjson
[RAW] Processing artist: pig1987
[RAW] Loaded: Overview.csv (365 rows)
[RAW] Date rollover: 2024 â†’ 2025
[RAW] Transformed to 365 JSON records
[RAW] Written 365 records â†’ Overview_2024-06-17_1750084991_pig1987_20250618_074348.ndjson
[RAW] Successfully processed 2 artists
[RAW] Completed: 2 artists processed
[INFO] Running cleaner: src\tiktok\cleaners\tiktok_raw2staging.py
[INFO] PROJECT_ROOT: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake
[INFO] RAW_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\raw\tiktok
[INFO] STAGING_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging
[STAGING] Loading 20250613: Overview_2024-06-12_1749649029_pig1987_20250613_072000.ndjson
[STAGING] Processed 20250613: 0 records
[STAGING] Loading 20250616: Overview_2024-06-15_1749916024_pig1987_20250616_084833.ndjson
[STAGING] Processed 20250616: 0 records
[STAGING] Loading 20250618: Overview_2024-06-17_1750084991_pig1987_20250618_074348.ndjson
[STAGING] Processed 20250618: 0 records
[STAGING] Total loaded: 1095 rows across 1 artists
[STAGING] Loaded existing staging: 763 rows
[STAGING] pig1987: 2 new records since 2025-06-14
[STAGING] Added 2 new records â†’ 765 total
[STAGING] Written to: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging\tiktok.csv
[STAGING] Completed: 765 records in staging
[INFO] Running cleaner: src\tiktok\cleaners\tiktok_staging2curated.py
[INFO] PROJECT_ROOT: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake
[INFO] STAGING_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging
[INFO] CURATED_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\curated\tiktok
[CURATED] Loaded staging: 765 rows from tiktok.csv
[CURATED] Aggregated to 765 rows
[CURATED] Written: tiktok_analytics_curated_20250618_074349.csv (765 rows)
[CLEANUP] Archived older curated files â†’ archive\tiktok
[CURATED] Completed: 765 curated records
[INFO] Running extractors for toolost
[INFO] Running extractor: src\toolost\extractors\toolost_scraper.py
[cookies] toolost: already imported â€“ skipping.
[TOOLOST] Please log in and complete any 2FA...
[TOOLOST] Authenticated dashboard detected!
[TOOLOST] Date picker not found.
Waiting for Spotify API call...
Saved spotify analytics to C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\raw\toolost\toolost_spotify_20250618_074359.json
Waiting for Apple Music API call...
Saved apple analytics to C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\raw\toolost\toolost_apple_20250618_074359.json
Data collection complete. You may now close the browser window.
[INFO] Running cleaners for toolost
[INFO] Running cleaner: src\toolost\cleaners\toolost_landing2raw.py
â†©ï¸Ž toolost_apple_20250522_124556.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_134925.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_135447.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_140337.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_141126.json       already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250522_124556.json     already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250526_135447.json     already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250526_140337.json     already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250526_141126.json     already in raw (hash match)

Summary: promoted=0, skipped/invalid=0
[INFO] Running cleaner: src\toolost\cleaners\toolost_raw2staging.py
Using Spotify file â†’ toolost_spotify_20250529_043724.json
Using Apple   file â†’ toolost_apple_20250529_043724.json
        date  spotify_streams  apple_streams  combined_streams
0 2025-02-07              215            2.0             217.0
1 2025-02-08              595            5.0             600.0
2 2025-02-09              456           15.0             471.0
3 2025-02-10              673           14.0             687.0
4 2025-02-11              843            3.0             846.0
ðŸ’¾ saved â†’ C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging\daily_streams_toolost.csv
âœ… QC passed â€“ totals align
[INFO] Running cleaner: src\toolost\cleaners\toolost_staging2curated.py
â†©ï¸Ž No changes â€“ curated already up-to-date.
[INFO] Running extractors for youtube
[INFO] Running cleaners for youtube
Generated C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\cronjob\run_datalake_cron_no_extractors.bat from C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\cronjob\run_datalake_cron.bat (extractor sections removed).

[INFO] Running C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\cronjob\run_datalake_cron_no_extractors.bat...
[INFO] Running extractors for common
[INFO] Running extractors for instagram
[INFO] Running cleaners for instagram
[INFO] Running extractors for linktree
[INFO] Running cleaners for linktree
[INFO] Running cleaner: src\linktree\cleaners\linktree_landing2raw.py
Traceback (most recent call last):
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\linktree\cleaners\linktree_landing2raw.py", line 88, in <module>
    main()
  File "C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\linktree\cleaners\linktree_landing2raw.py", line 82, in main
    raise RuntimeError("No records processed; aborting.")
RuntimeError: No records processed; aborting.
[INFO] Running cleaner: src\linktree\cleaners\linktree_raw2staging.py
[STAGING] Written â†’ linktree_analytics_staging_20250618_074420.csv  (383 rows)
[INFO] Running cleaner: src\linktree\cleaners\linktree_staging2curated.py
C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\src\linktree\cleaners\linktree_staging2curated.py:28: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context("mode.use_inf_as_na", True):
[CURATED] CSV â†’ linktree_analytics_curated_20250618_074421.csv  (380 rows)
[CURATED] Parquet â†’ linktree_analytics_curated_20250618_074421.parquet
[CLEANUP] Archived older curated files â†’ archive\linktree
[INFO] Running extractors for mailchimp
[INFO] Running cleaners for mailchimp
[INFO] Running extractors for metaads
[INFO] Running cleaners for metaads
[INFO] Running cleaner: src\metaads\cleaners\metaads_landing2raw.py
â†©ï¸Ž meta_ads_dump_20250529_112751 already in RAW
â†©ï¸Ž meta_ads_dump_20250529_113628 already in RAW
â†©ï¸Ž meta_ads_dump_20250529_131842 already in RAW
â†©ï¸Ž meta_ads_dump_20250605_152903 already in RAW
â†©ï¸Ž meta_ads_dump_20250609_143936 already in RAW
â†©ï¸Ž meta_ads_dump_20250611_183340 already in RAW
â†©ï¸Ž meta_ads_dump_20250611_183837 already in RAW
â†©ï¸Ž meta_ads_dump_20250613_133651 already in RAW
â†©ï¸Ž meta_ads_dump_20250616_154645 already in RAW
â†©ï¸Ž meta_ads_dump_20250618_144100 already in RAW
Summary: 0 new dump(s) promoted.
[INFO] Running cleaner: src\metaads\cleaners\metaads_raw2staging.py
Rows â†’ campaigns 17, adsets 51, ads 74, insights 51
ads_flat cols: ['ad_id', 'campaign_id', 'adset_id', 'ad_name', 'status', 'effective_status', 'created_time', 'updated_time', 'creative_id', 'tracking_specs']
campaigns_ cols: ['campaign_id', 'campaign_name', 'campaign_status', 'campaign_objective', 'start_time', 'created_time', 'updated_time']
adsets_ cols: ['adset_id', 'adset_name', 'adset_status', 'adset_daily_budget', 'adset_lifetime_budget', 'bid_strategy', 'targeting', 'optimization_goal', 'start_time', 'pacing_type', 'created_time', 'updated_time']
âœ… tidy_metaads â†’ C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging\tidy_metaads.csv  (rows: 74)
          campaign_id  ...                                     tracking_specs
0  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
1  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
2  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
3  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...
4  120224907266750075  ...  [{"action.type": ["offsite_conversion"], "fb_p...

[5 rows x 38 columns]
[INFO] Running cleaner: src\metaads\cleaners\metaads_staging2curated.py
â†©ï¸Ž No changes â€“ curated already up-to-date.
[INFO] Running extractors for spotify
[INFO] Running cleaners for spotify
[INFO] Running cleaner: src\spotify\cleaners\spotify_staging2curated.py
[ERROR] [STAGING] No CSV files found to process.
[INFO] Running extractors for tiktok
[INFO] Running cleaners for tiktok
[INFO] Running cleaner: src\tiktok\cleaners\tiktok_landing2raw.py
[INFO] PROJECT_ROOT: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake
[INFO] LANDING_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\landing\tiktok\analytics
[INFO] RAW_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\raw\tiktok
[RAW] Found 2 artists: ['zone.a0', 'pig1987']
[RAW] Processing artist: zone.a0
[RAW] Loaded: Overview.csv (365 rows)
[RAW] Date rollover: 2024 â†’ 2025
[RAW] Transformed to 365 JSON records
[RAW] Written 365 records â†’ Overview_2024-06-12_1749649062_zone.a0_20250618_074423.ndjson
[RAW] Processing artist: pig1987
[RAW] Loaded: Overview.csv (365 rows)
[RAW] Date rollover: 2024 â†’ 2025
[RAW] Transformed to 365 JSON records
[RAW] Written 365 records â†’ Overview_2024-06-17_1750084991_pig1987_20250618_074423.ndjson
[RAW] Successfully processed 2 artists
[RAW] Completed: 2 artists processed
[INFO] Running cleaner: src\tiktok\cleaners\tiktok_raw2staging.py
[INFO] PROJECT_ROOT: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake
[INFO] RAW_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\raw\tiktok
[INFO] STAGING_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging
[STAGING] Loading 20250613: Overview_2024-06-12_1749649029_pig1987_20250613_072000.ndjson
[STAGING] Processed 20250613: 0 records
[STAGING] Loading 20250616: Overview_2024-06-15_1749916024_pig1987_20250616_084833.ndjson
[STAGING] Processed 20250616: 0 records
[STAGING] Loading 20250618: Overview_2024-06-17_1750084991_pig1987_20250618_074423.ndjson
[STAGING] Processed 20250618: 0 records
[STAGING] Total loaded: 1095 rows across 1 artists
[STAGING] Loaded existing staging: 765 rows
[STAGING] pig1987: no new records
[STAGING] No new records to add
[STAGING] Written to: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging\tiktok.csv
[STAGING] Completed: 765 records in staging
[INFO] Running cleaner: src\tiktok\cleaners\tiktok_staging2curated.py
[INFO] PROJECT_ROOT: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake
[INFO] STAGING_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging
[INFO] CURATED_DIR: C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\curated\tiktok
[CURATED] Loaded staging: 765 rows from tiktok.csv
[CURATED] Aggregated to 765 rows
[CURATED] Written: tiktok_analytics_curated_20250618_074425.csv (765 rows)
[CLEANUP] Archived older curated files â†’ archive\tiktok
[CURATED] Completed: 765 curated records
[INFO] Running extractors for toolost
[INFO] Running cleaners for toolost
[INFO] Running cleaner: src\toolost\cleaners\toolost_landing2raw.py
â†©ï¸Ž toolost_apple_20250522_124556.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_134925.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_135447.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_140337.json       already in raw (hash match)
â†©ï¸Ž toolost_apple_20250526_141126.json       already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250522_124556.json     already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250526_135447.json     already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250526_140337.json     already in raw (hash match)
â†©ï¸Ž toolost_spotify_20250526_141126.json     already in raw (hash match)

Summary: promoted=0, skipped/invalid=0
[INFO] Running cleaner: src\toolost\cleaners\toolost_raw2staging.py
Using Spotify file â†’ toolost_spotify_20250529_043724.json
Using Apple   file â†’ toolost_apple_20250529_043724.json
        date  spotify_streams  apple_streams  combined_streams
0 2025-02-07              215            2.0             217.0
1 2025-02-08              595            5.0             600.0
2 2025-02-09              456           15.0             471.0
3 2025-02-10              673           14.0             687.0
4 2025-02-11              843            3.0             846.0
ðŸ’¾ saved â†’ C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\staging\daily_streams_toolost.csv
âœ… QC passed â€“ totals align
[INFO] Running cleaner: src\toolost\cleaners\toolost_staging2curated.py
â†©ï¸Ž No changes â€“ curated already up-to-date.
[INFO] Running extractors for youtube
[INFO] Running cleaners for youtube
Press any key to continue . . .
[INFO] C:\Users\Earth\BEDROT PRODUCTIONS\BEDROT DATA LAKE\data_lake\cronjob\run_datalake_cron_no_extractors.bat exited with code 0